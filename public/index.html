<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>http stt site</title>
<style>
body { font-family: sans-serif; max-width: 600px; margin: 1rem auto; text-align: center; }
button { padding: 10px 20px; margin: 10px; font-size: 1rem; }
#log { white-space: pre-wrap; background: #111; color: #0f0; padding: 1em; height: 200px; overflow-y: auto; text-align: left; }
</style>
</head>
<body>
<h2>Dubix stt</h2>
<p>This page simulates the ESP32 client using AudioWorklet.</p>
<button id="startBtn">üéôÔ∏è Start</button>
<button id="stopBtn" disabled>üõë Stop</button>
<div id="log"></div>

<script>
const id = 'browser';
const sampleRate = 16000;
let audioCtx, processorNode, mediaStream, stopped = false;
const logBox = document.getElementById('log');
const startBtn = document.getElementById('startBtn');
const stopBtn = document.getElementById('stopBtn');

function log(msg) {
  logBox.textContent += msg + '\n';
  logBox.scrollTop = logBox.scrollHeight;
}

// === AudioWorklet Processor ===
const workletCode = `
class PCMProcessor extends AudioWorkletProcessor {
  constructor() {
    super();
    this._buffer = [];
    this._frameCount = 0;
  }

  process(inputs) {
    const input = inputs[0];
    if (!input || !input[0]) return true;
    const channelData = input[0];
    const buffer = new ArrayBuffer(channelData.length * 2);
    const view = new DataView(buffer);
    for (let i = 0; i < channelData.length; i++) {
      let s = Math.max(-1, Math.min(1, channelData[i]));
      view.setInt16(i * 2, s * 0x7fff, true);
    }
    this.port.postMessage(buffer);
    return true;
  }
}
registerProcessor('pcm-processor', PCMProcessor);
`;

async function start() {
  stopped = false;
  startBtn.disabled = true;
  stopBtn.disabled = false;
  log('Requesting mic access...');

  mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
  audioCtx = new AudioContext({ sampleRate });

  const blob = new Blob([workletCode], { type: 'application/javascript' });
  const workletURL = URL.createObjectURL(blob);
  await audioCtx.audioWorklet.addModule(workletURL);

  const source = audioCtx.createMediaStreamSource(mediaStream);
  processorNode = new AudioWorkletNode(audioCtx, 'pcm-processor');
  source.connect(processorNode);
  processorNode.connect(audioCtx.destination);

  processorNode.port.onmessage = async (e) => {
    if (stopped) return;
    const pcmChunk = e.data;
    try {
      await fetch(`/stream?id=${id}&sample_rate=${sampleRate}`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/octet-stream' },
        body: pcmChunk
      });
    } catch (err) {
      log('POST failed: ' + err);
    }
  };

  log('üéôÔ∏è Mic started streaming...');
  pollTranscript();
}

async function stop() {
  stopped = true;
  stopBtn.disabled = true;
  startBtn.disabled = false;
  if (processorNode) processorNode.disconnect();
  if (audioCtx) await audioCtx.close();
  if (mediaStream) mediaStream.getTracks().forEach(t => t.stop());
  log('üõë Mic stopped.');
}

async function pollTranscript() {
  while (!stopped) {
    try {
      const resp = await fetch(`/transcript?id=${id}`);
      const data = await resp.json();
      if (data.ready && data.transcript) {
        log('üìù Transcript: ' + data.transcript);
      }
    } catch (err) {
      log('Poll error: ' + err);
    }
    await new Promise(r => setTimeout(r, 1000));
  }
}

startBtn.onclick = start;
stopBtn.onclick = stop;
</script>
</body>
</html>
